name: Publish and inventory

on:
  workflow_dispatch: {}
  schedule:
    - cron: '*/30 * * * *'   # every 30 minutes

permissions:
  contents: write

jobs:
  snapshot-and-inventory:
    runs-on: ubuntu-latest
    env:
      ROOT: Explorer
      OUT_CSV: docs/ProjectInventory.csv
      OUT_LINKS: docs/ProjectFileLinks.txt
      GIST_DESCRIPTION: "RizzCity .luau snapshot (private gist)"
      GH_PAT: ${{ secrets.GH_PAT }}

    steps:
      - name: Checkout repo (full history)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: false

      - name: Ensure docs folder exists
        run: mkdir -p docs

      - name: Setup Python 3
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install Python requirements
        run: python3 -m pip install --user requests

      - name: Normalize newlines & prepare files (in-workspace)
        # This normalizes CRLF/CR -> LF in-place for .luau files
        run: |
          set -euo pipefail
          if [ ! -d "${{ env.ROOT }}" ]; then
            echo "Root '${{ env.ROOT }}' not found, skipping normalization"
            exit 0
          fi
          find "${{ env.ROOT }}" -type f -name "*.luau" -print0 | while IFS= read -r -d '' file; do
            perl -0777 -pe 's/\r\n?/\n/g' "$file" > "${file}.normalized" && mv "${file}.normalized" "$file" || true
          done
          echo "Normalized newlines for .luau files (if any)."

      - name: Create gist snapshot and write ProjectInventory.csv
        env:
          ROOT: ${{ env.ROOT }}
          OUT_CSV: ${{ env.OUT_CSV }}
          GIST_DESCRIPTION: ${{ env.GIST_DESCRIPTION }}
          GH_PAT: ${{ env.GH_PAT }}
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import os, json, requests, csv, sys

          ROOT = os.environ.get("ROOT", "Explorer")
          OUT_CSV = os.environ.get("OUT_CSV", "docs/ProjectInventory.csv")
          DESC = os.environ.get("GIST_DESCRIPTION", "luau snapshot")
          TOKEN = os.environ.get("GH_PAT")

          if not TOKEN:
              print("ERROR: GH_PAT not set", file=sys.stderr)
              sys.exit(2)

          repo_root = os.getcwd()
          files_payload = {}
          inventory = []

          # collect .luau files deterministically
          for dirpath, dirnames, filenames in os.walk(ROOT):
              filenames.sort()
              for fn in filenames:
                  if not fn.lower().endswith(".luau"):
                      continue
                  full = os.path.join(dirpath, fn)
                  rel = os.path.relpath(full, repo_root).replace("\\", "/")
                  with open(full, "rb") as fh:
                      raw = fh.read()
                  try:
                      text = raw.decode("utf-8")
                  except:
                      text = raw.decode("utf-8", errors="replace")
                  # normalize newlines (just in case)
                  normalized = text.replace("\r\n", "\n").replace("\r", "\n")
                  # ensure consistent formatting of file content in gist payload
                  files_payload[rel.replace("/", "__")] = {"content": normalized}
                  line_count = len(normalized.splitlines())
                  byte_size = len(normalized.encode("utf-8"))
                  inventory.append({
                      "filename": os.path.basename(rel),
                      "repo_path": rel,
                      "gist_filename": rel.replace("/", "__"),
                      "line_count": line_count,
                      "byte_size": byte_size
                  })

          if not files_payload:
              print("No .luau files found under", ROOT)
              os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)
              with open(OUT_CSV, "w", newline="", encoding="utf-8") as f:
                  w = csv.writer(f)
                  w.writerow(["filename","repo_path","gist_filename","raw_gist_url","line_count","byte_size"])
              print("Wrote empty inventory to", OUT_CSV)
              sys.exit(0)

          # create private gist
          payload = {"description": DESC, "public": False, "files": files_payload}
          headers = {"Authorization": f"token {TOKEN}", "Accept": "application/vnd.github+json"}
          r = requests.post("https://api.github.com/gists", headers=headers, data=json.dumps(payload))
          if r.status_code not in (200,201):
              print("Failed creating gist:", r.status_code, r.text, file=sys.stderr)
              sys.exit(3)
          gist = r.json()
          gist_files_resp = gist.get("files", {})

          # write inventory CSV and include raw_gist_url from gist response
          os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)
          with open(OUT_CSV, "w", newline="", encoding="utf-8") as f:
              w = csv.writer(f)
              w.writerow(["filename","repo_path","gist_filename","raw_gist_url","line_count","byte_size"])
              for it in inventory:
                  gf = gist_files_resp.get(it["gist_filename"], {})
                  raw_url = gf.get("raw_url", "")
                  w.writerow([it["filename"], it["repo_path"], it["gist_filename"], raw_url, it["line_count"], it["byte_size"]])

          print("Wrote inventory to", OUT_CSV)
          print("Gist URL:", gist.get("html_url"))
          PY

      - name: Generate docs/ProjectFileLinks.txt (map repo_path -> raw_url)
        env:
          OUT_CSV: ${{ env.OUT_CSV }}
          OUT_LINKS: ${{ env.OUT_LINKS }}
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import csv, os, sys
          csv_path = os.environ.get("OUT_CSV", "docs/ProjectInventory.csv")
          out_path = os.environ.get("OUT_LINKS", "docs/ProjectFileLinks.txt")
          if not os.path.exists(csv_path):
              print("Missing", csv_path, file=sys.stderr)
              sys.exit(1)
          rows = []
          with open(csv_path, newline='', encoding='utf-8') as f:
              reader = csv.DictReader(f)
              for r in reader:
                  repo_path = (r.get("repo_path") or "").strip()
                  raw = (r.get("raw_gist_url") or "").strip()
                  rows.append((repo_path, raw))
          # write mapping file (one per line: <repo_path> <raw_url>)
          os.makedirs(os.path.dirname(out_path), exist_ok=True)
          with open(out_path, "w", encoding="utf-8") as f:
              for repo_path, raw in rows:
                  f.write(f"{repo_path} {raw}\n")
          print("Wrote", out_path)
          PY

      - name: Commit & push inventory + links (if changed)
        env:
          GH_PAT: ${{ env.GH_PAT }}
          OUT_CSV: ${{ env.OUT_CSV }}
          OUT_LINKS: ${{ env.OUT_LINKS }}
        run: |
          set -euo pipefail
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          git add "${OUT_CSV}" "${OUT_LINKS}" || true

          if git diff --staged --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "chore: regenerate ProjectInventory.csv + ProjectFileLinks.txt (auto)"

          # Use GH_PAT for authenticated operations (set origin to token URL)
          remote_url="https://x-access-token:${GH_PAT}@github.com/${GITHUB_REPOSITORY}.git"
          git remote set-url origin "$remote_url"

          # Fetch remote main and rebase our commit on top to avoid non-fast-forward
          git fetch origin main
          # If the remote has new commits, rebase our local branch onto it.
          # If rebase fails, fall back to merge to avoid leaving job stuck (but fail on conflicts).
          if git rev-parse --verify origin/main >/dev/null 2>&1; then
            git rebase origin/main || git pull --rebase origin main
          fi

          # Finally push
          git push origin HEAD:main
